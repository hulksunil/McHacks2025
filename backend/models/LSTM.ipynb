{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Import necessary libraries for data processing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Import necessary libraries for model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.metrics import Precision, Recall, F1Score, AUC\n",
    "\n",
    "# Import necessary libraries for evaluation\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a CSV file\n",
    "market_data_1 = pd.read_csv('../../backend/data/TrainingData/Period1/A/market_data_A_0.csv')\n",
    "market_data_2 = pd.read_csv('../../backend/data/TrainingData/Period1/A/market_data_A_1.csv')\n",
    "market_data = pd.concat([market_data_1, market_data_2])\n",
    "\n",
    "# Load the trade data from a CSV file\n",
    "trade_data = pd.read_csv('../../backend/data/TrainingData/Period1/A/trade_data__A.csv')\n",
    "\n",
    "# merge the data on the nearest timestamp\n",
    "merged_data = pd.merge_asof(market_data.sort_values('timestamp'),\n",
    "    trade_data.sort_values('timestamp'),\n",
    "    by='timestamp',\n",
    "    direction='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the spread between the market and trade data\n",
    "merged_data['spread'] = merged_data['askPrice'] - merged_data['bidPrice']\n",
    "\n",
    "# Add a moving average of the spread\n",
    "merged_data['bidPrice_ma'] = merged_data['bidPrice'].rolling(window=5).mean()\n",
    "merged_data['askPrice_ma'] = merged_data['askPrice'].rolling(window=5).mean()\n",
    "merged_data.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomalise Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to a range of 0 to 1\n",
    "scaler = MinMaxScaler()\n",
    "features = ['bidVolume', 'bidPrice', 'askVolume', 'askPrice', 'spread', 'bidPrice_ma', 'askPrice_ma']\n",
    "scaler.fit(merged_data[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define timesteps\n",
    "timesteps = 10\n",
    "\n",
    "# Prepare input (x) and output (y)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(merged_data) - timesteps):\n",
    "    x.append(merged_data[features].iloc[i:i + timesteps].values)\n",
    "    y.append(merged_data['bidPrice'].iloc[i + timesteps])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the input data\n",
    "input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=input_shape, return_sequences=True))\n",
    "model.add(Dense(1, activation='Linear')) # TODO:Adjust the activation function to sigmoid if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model for training\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae']) # TODO:Adjust the loss function to binary_crossentropy if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred_original = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Convert predictions to binary\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other resources code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('LSTM_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in tensoflow model\n",
    "model.save('LSTM_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
